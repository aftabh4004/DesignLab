{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport numpy as np\n\nnltk.download('punkt')\n\n\n!pip install emoji==1.5.0\n# Intersection code, the DataFrame should be empty\nimport re\nimport pickle\nimport emoji\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\n\nword_to_index = {}","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:08.848679Z","iopub.execute_input":"2023-04-12T09:30:08.849931Z","iopub.status.idle":"2023-04-12T09:30:22.329585Z","shell.execute_reply.started":"2023-04-12T09:30:08.849881Z","shell.execute_reply":"2023-04-12T09:30:22.327477Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nRequirement already satisfied: emoji==1.5.0 in /opt/conda/lib/python3.7/site-packages (1.5.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Intersection code, the DataFrame should be empty","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/testdatadeslab/hindi_test.csv\")\ndf_train = pd.read_csv(\"/kaggle/input/traindatadeslab/hindi_train_val.csv\")\n\ndf_test = df_test.merge(df_train, on=\"text\")\ndf_test","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:22.332806Z","iopub.execute_input":"2023-04-12T09:30:22.333243Z","iopub.status.idle":"2023-04-12T09:30:22.535134Z","shell.execute_reply.started":"2023-04-12T09:30:22.333197Z","shell.execute_reply":"2023-04-12T09:30:22.533742Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [label_x, text, label_y]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label_x</th>\n      <th>text</th>\n      <th>label_y</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"\n# TEST = False\n# file = \"/kaggle/input/traindatadeslab/hindi_train_val.csv\"\n\nTEST = True\nfile = \"/kaggle/input/testdatadeslab/hindi_test.csv\"\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:22.536598Z","iopub.execute_input":"2023-04-12T09:30:22.537088Z","iopub.status.idle":"2023-04-12T09:30:22.544360Z","shell.execute_reply.started":"2023-04-12T09:30:22.537037Z","shell.execute_reply":"2023-04-12T09:30:22.542724Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Helper functions","metadata":{}},{"cell_type":"code","source":"def extract_emojis(s):\n    return ''.join((' '+c+' ') if c in emoji.UNICODE_EMOJI['en'] else c for c in s)\n\n\n\ndef word_mapping_train(sentence):\n    mapping = []\n    for word in sentence:\n        try:\n            mapping.append(word_to_index[word])\n        except:\n            word_to_index[word] = len(word_to_index)\n            mapping.append(word_to_index[word])\n    return mapping\n\ndef word_mapping_test(sentence):\n    mapping = []\n    for word in sentence:\n        try:\n            mapping.append(word_to_index[word])\n        except:\n            pass\n    return mapping\n","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:22.548677Z","iopub.execute_input":"2023-04-12T09:30:22.549132Z","iopub.status.idle":"2023-04-12T09:30:22.559114Z","shell.execute_reply.started":"2023-04-12T09:30:22.549092Z","shell.execute_reply":"2023-04-12T09:30:22.556760Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"def load_data(file, test=False):\n    df = pd.read_csv(file)\n\n    df[\"text\"] = df[\"text\"].apply(extract_emojis)\n    df[\"text\"] = df[\"text\"].apply(nltk.word_tokenize)\n    \n    mapping_function = word_mapping_train if not test else word_mapping_test\n    df[\"text\"] = df[\"text\"].apply(mapping_function)\n    \n    return df\n\ndef tfidfFitTransform(df):\n    \n    words_indexs = df[\"text\"].values\n    words_vectors = np.zeros((len(df), len(word_to_index)), dtype=int)\n\n    for i, sentence in enumerate(words_indexs):\n        words_vectors[i][sentence] += 1\n\n\n    np_words_vectors = words_vectors\n    words_vectors = list(words_vectors)\n    \n    idf_vector = np.log(len(np_words_vectors)/np.sum(np_words_vectors, axis=0))\n    \n   \n    tf_idf = np_words_vectors * idf_vector\n    return tf_idf, idf_vector\n\ndef tfidfTransform(df, idf_vector):\n    words_indexs = df[\"text\"].values\n    words_vectors = np.zeros((len(df), len(word_to_index)), dtype=int)\n\n    for i, sentence in enumerate(words_indexs):\n        words_vectors[i][sentence] += 1\n\n    np_words_vectors = words_vectors\n    tf_idf = np_words_vectors * idf_vector\n    return tf_idf\n    \n\ndef remove_stopwords(tf_idf, idf_vector):\n    \n    stopwords = np.logical_or(idf_vector < 2.5, idf_vector > 8.5) \n    stopword_index = []\n    for word, index in word_to_index.items():\n        if stopwords[index] != 0:\n            stopword_index.append(index)\n\n    tf_idf = np.delete(tf_idf, stopword_index, axis = 1)\n    \n    return tf_idf\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:22.561291Z","iopub.execute_input":"2023-04-12T09:30:22.561754Z","iopub.status.idle":"2023-04-12T09:30:22.577632Z","shell.execute_reply.started":"2023-04-12T09:30:22.561710Z","shell.execute_reply":"2023-04-12T09:30:22.576294Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# KNN","metadata":{}},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def training():\n    df = load_data(file, test=False)\n    tf_idf, idf_vector = tfidfFitTransform(df)\n    tf_idf = remove_stopwords(tf_idf, idf_vector)\n    \n    X = tf_idf\n    y = df[['label']]\n    y = np.array(y).reshape((-1,))\n\n    best_k = 0\n    K = range(2,21)\n    \n    score = []\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\n    for k in K:\n        knn = KNeighborsClassifier(n_neighbors = k)\n        knn.fit(X_train,y_train)\n        acc = knn.score(X_test,y_test)\n        score.append(acc)\n        print(f\"k = {k} acc: {acc}\")\n        \n    best_k = np.argmax(np.array(score)) + 2\n    print()\n    print(f\"best_k: {best_k} acc: {score[best_k - 2]}\")\n    \n    best_knn = KNeighborsClassifier(n_neighbors = k)\n    best_knn.fit(X,y)\n    \n    pickle.dump(best_knn, open(\"knn.sav\", 'wb'))\n    \n    pickle.dump(word_to_index, open(\"word_to_index.sav\", 'wb'))\n    pickle.dump(idf_vector, open(\"idf_vector.sav\", 'wb'))\n    print(\"Model Saved\")","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:22.579841Z","iopub.execute_input":"2023-04-12T09:30:22.581999Z","iopub.status.idle":"2023-04-12T09:30:22.599839Z","shell.execute_reply.started":"2023-04-12T09:30:22.581897Z","shell.execute_reply":"2023-04-12T09:30:22.597829Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"def testing():\n    print(\"Testing...\")\n    global word_to_index \n    word_to_index = pickle.load(open(\"word_to_index.sav\", 'rb'))\n    idf_vector = pickle.load(open(\"idf_vector.sav\", 'rb'))\n    knn = pickle.load(open(\"knn.sav\", 'rb'))\n    \n    idf_vector = np.array(idf_vector)\n    \n    print(\"Model loaded\")\n    \n    df = load_data(file, test=True)\n    \n    tf_idf = tfidfTransform(df, idf_vector)\n    \n    tf_idf = remove_stopwords(tf_idf, idf_vector)\n    \n    X = tf_idf\n    y = df[['label']]\n    y = np.array(y).reshape((-1,))\n    \n    pred = knn.predict(X)\n    return  pred, y","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:22.602429Z","iopub.execute_input":"2023-04-12T09:30:22.603294Z","iopub.status.idle":"2023-04-12T09:30:22.619331Z","shell.execute_reply.started":"2023-04-12T09:30:22.603234Z","shell.execute_reply":"2023-04-12T09:30:22.617993Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"if TEST:\n    pred, y_true = testing()\n    print(classification_report(y_true, pred))\n    y_pred_df = pd.Series(pred)\n    result_csv = y_pred_df.to_csv(\"resultKNN.csv\", index=False)\n    print(\"Result saved in resultKNN.csv\")\nelse:\n    training()","metadata":{"execution":{"iopub.status.busy":"2023-04-12T09:30:22.620610Z","iopub.execute_input":"2023-04-12T09:30:22.621115Z","iopub.status.idle":"2023-04-12T09:30:52.298096Z","shell.execute_reply.started":"2023-04-12T09:30:22.621063Z","shell.execute_reply":"2023-04-12T09:30:52.296797Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Testing...\nModel loaded\n              precision    recall  f1-score   support\n\n           0       0.82      0.55      0.66      3496\n           1       0.64      0.87      0.74      3232\n\n    accuracy                           0.70      6728\n   macro avg       0.73      0.71      0.70      6728\nweighted avg       0.73      0.70      0.70      6728\n\nResult saved in resultKNN.csv\n","output_type":"stream"}]}]}